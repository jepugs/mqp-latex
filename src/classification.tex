In this chapter, we define label prediction methods and show how they can
be applied on graphs. We present different problems we can solve using
label prediction methods and how we can incorporate graph metrics, such as
the Diffusion State Distance (DSD), into these methods. We use the terms
label prediction methods and vertex classifiers interchangeably.

% severely fix
\section{Problem Definition}
\label{sec:label_prediction_methods}
We begin by presenting definitions relating to labels of graphs.

% Use minus sign for set subtract
% fix censoring definition/ remove? move to simulations
\begin{definition}
A \textbf{partially labeled graph} is a graph $G$ and a function
$c : V_{G_p} \to S$, where $S$ is an arbitrary set of labels, and
$V_{G_p} \subseteq V_G$ with
$|V_{G_p}| = \left\lfloor{p \cdot |V_G|}\right\rfloor$, $0 \leq p \leq 1$.

The set $V_G \setminus V_{G_p}$ is called the set of \textbf{unlabeled} 
vertices of $G$.

The function $c$ is called a \textbf{partial labeling} of $G$.
\end{definition}

\begin{definition}
A \textbf{censoring} of a labeled graph $G$ and its labeling function
$c : V_G \to S$ is a set $V_{G_c}$ and a function
$c_p: V_G \setminus V_{G_c} \to S$ such that $c_p$ is a partial labeling
of $G$.

The function $c$ of the labeled graph $G$ is called the
\textbf{ground truth labeling} of the censoring of $G$.

Note that the set $V_{G_c}$ is the set of unlabeled vertices of the
partial labeling of $G$.
\end{definition}

Given a partially labeled graph $G$, a censoring $(V_{G_c}, c_{censor})$
of $G$, and a ground truth labeling $c_{ground truth}$ of $G$, a 
\textbf{label prediction method} is an algorithm that attempts to correctly 
guess the labels of the unlabeled vertices $V_{G_c}$ with respect to the
ground truth labels $c_{ground truth}(v), v \in V_{G_c}$.

We now discuss label prediction methods that we considered for our 
simulations in Chapter 6.

% Fix wording make more mathematical
\subsection{Majority Voting Algorithm}
Cao, Zhang, Park, Daniels, Crovella, Cowen, and Hescott~\cite{10.1371/journal.pone.0076339}
mention a simple prediction method called the neighborhood majority voting
algorithm. We considered two implementations of this algorithm. One 
implementation considers each vertex $v \in V$ and all neighbors of $v$
within an $\varepsilon$ distance from $v$ (a ball of radius $\varepsilon$).
The $\varepsilon$ distance depends on the metric under consideration, and
may be changed as a parameter. In an unweighted scheme, each neighbor
within the ball of radius $\varepsilon$ votes equally for their own label.
In a weighted scheme, each neighbor gets a vote proportional to the
reciprocal of their distance to the vertex $v$ in consideration. The other
implementation of this algorithm considers each vertex $v \epsilon V$ and
the $k$-nearest neighbors of $v$. Voting is done similarly in both an
unweighted and weighted scheme.

There are other prediction methods that exist, such as the $\chi^{2}$
neighborhood algorithm, the multi-way cut algorithm, and the functional
flow algorithm~\cite{10.1371/journal.pone.0076339}. However, we only
consider the weighted majority voting algorithm for our simulations in
order to keep the intuition behind results of this algorithm simple.
